{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b302a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from matplotlib import pyplot\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "import io\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c2e9433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# resizing the images\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Set the desired size\n",
    "size = (200, 200)\n",
    "\n",
    "# Loop through the directories and resize the images\n",
    "for folder in ['dogs_vs_squirrel/test/dogs/', 'dogs_vs_squirrel/test/squirrel/']:\n",
    "    for filename in os.listdir(folder):\n",
    "        image_path = os.path.join(folder, filename)\n",
    "        with Image.open(image_path) as image:\n",
    "            resized_image = image.resize(size)\n",
    "            resized_image.save(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "35ce7f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ee7274a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "folder_path = 'dogs_vs_squirrel/test/squirrel/'\n",
    "# Loop over all the files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file is an image file\n",
    "    if filename.endswith('.png'):\n",
    "        # Open the image file using PIL\n",
    "        image = Image.open(os.path.join(folder_path, filename))\n",
    "        # Append the image to the list\n",
    "        images.append(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b27c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3344d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_to_image(figure):\n",
    "    buf = io.BytesIO()\n",
    "    pyplot.savefig(buf, format='png')\n",
    "    # Closing the figure prevents it from being displayed directly inside\n",
    "    # the notebook.\n",
    "    pyplot.close(figure)\n",
    "    buf.seek(0)\n",
    "    # Convert PNG buffer to TF image\n",
    "    image = tf.image.decode_png(buf.getvalue(), channels=4)\n",
    "    # Add the batch dimension\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    return image\n",
    "\n",
    "def image_grid(predictions, images):\n",
    "    figure = pyplot.figure(figsize=(10, 10))\n",
    "    for i in range(40):\n",
    "            # Start next subplot.\n",
    "        pyplot.subplot(5, 8, i + 1, title= 'Dogs' if predictions[i] < 0.5 else 'Squirrel')\n",
    "        pyplot.xticks([])\n",
    "        pyplot.yticks([])\n",
    "        pyplot.grid(False)\n",
    "        pyplot.imshow(images[i])\n",
    "\n",
    "    return figure\n",
    "\n",
    "def load_image(filename):\n",
    "     # load the image\n",
    "    img = load_img(filename, target_size=(200, 200))\n",
    "    # convert to array\n",
    "    img = img_to_array(img)\n",
    "    # reshape into a single sample with 3 channels\n",
    "    img = img.reshape(1, 200, 200, 3)\n",
    "    # center pixel data\n",
    "    img = img.astype('float32')\n",
    "    img = img - [123.68, 116.779, 103.939]\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e77cda0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54ed5610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an array of test images\n",
    "\n",
    "for i in range(81, 101):\n",
    "    # load the image\n",
    "    img = load_image('dogs_vs_squirrel/test/dogs/' +'dogs_' + str(i) + '.png')\n",
    "    # store loaded image\n",
    "    test_images.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ff0a94e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "703345b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG 1 Block\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    " # compile model\n",
    "opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg1_callback = keras.callbacks.TensorBoard(log_dir=\"logs/vgg1_callback_dir\", update_freq = 'batch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "863f3795",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot diagnostic learning curves\n",
    "def summarize_diagnostics(history, text):\n",
    "     # plot loss\n",
    "    pyplot.subplot(211)\n",
    "    pyplot.title('Cross Entropy Loss')\n",
    "    pyplot.plot(history.history['loss'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_loss'], color='orange', label='test')\n",
    "    # plot accuracy\n",
    "    pyplot.subplot(212)\n",
    "    pyplot.title('Classification Accuracy')\n",
    "    pyplot.plot(history.history['accuracy'], color='blue', label='train')\n",
    "    pyplot.plot(history.history['val_accuracy'], color='orange', label='test')\n",
    "    # save plot to file\n",
    "    pyplot.savefig(text + 'plot.png')\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd3fbe25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n",
      "Epoch 1/18\n",
      "2/2 - 4s - loss: 1.7817 - accuracy: 0.4500 - val_loss: 1.0808 - val_accuracy: 0.5000 - 4s/epoch - 2s/step\n",
      "Epoch 2/18\n",
      "2/2 - 3s - loss: 1.0586 - accuracy: 0.5000 - val_loss: 0.6765 - val_accuracy: 0.5500 - 3s/epoch - 1s/step\n",
      "Epoch 3/18\n",
      "2/2 - 3s - loss: 0.6859 - accuracy: 0.5437 - val_loss: 0.6919 - val_accuracy: 0.5000 - 3s/epoch - 1s/step\n",
      "Epoch 4/18\n",
      "2/2 - 3s - loss: 0.6831 - accuracy: 0.5125 - val_loss: 0.6827 - val_accuracy: 0.5250 - 3s/epoch - 1s/step\n",
      "Epoch 5/18\n",
      "2/2 - 3s - loss: 0.6843 - accuracy: 0.5250 - val_loss: 0.6880 - val_accuracy: 0.5000 - 3s/epoch - 1s/step\n",
      "Epoch 6/18\n",
      "2/2 - 3s - loss: 0.6534 - accuracy: 0.6750 - val_loss: 0.6704 - val_accuracy: 0.6000 - 3s/epoch - 1s/step\n",
      "Epoch 7/18\n",
      "2/2 - 3s - loss: 0.6297 - accuracy: 0.7375 - val_loss: 0.6621 - val_accuracy: 0.5750 - 3s/epoch - 1s/step\n",
      "Epoch 8/18\n",
      "2/2 - 3s - loss: 0.6326 - accuracy: 0.6562 - val_loss: 0.7180 - val_accuracy: 0.5500 - 3s/epoch - 1s/step\n",
      "Epoch 9/18\n",
      "2/2 - 3s - loss: 0.7063 - accuracy: 0.5375 - val_loss: 0.7110 - val_accuracy: 0.5500 - 3s/epoch - 1s/step\n",
      "Epoch 10/18\n",
      "2/2 - 3s - loss: 0.7364 - accuracy: 0.5562 - val_loss: 0.6538 - val_accuracy: 0.5750 - 3s/epoch - 1s/step\n",
      "Epoch 11/18\n",
      "2/2 - 3s - loss: 0.6810 - accuracy: 0.6187 - val_loss: 0.7150 - val_accuracy: 0.5750 - 3s/epoch - 1s/step\n",
      "Epoch 12/18\n",
      "2/2 - 3s - loss: 0.6763 - accuracy: 0.6000 - val_loss: 0.7333 - val_accuracy: 0.5500 - 3s/epoch - 1s/step\n",
      "Epoch 13/18\n",
      "2/2 - 3s - loss: 0.6271 - accuracy: 0.6625 - val_loss: 0.7499 - val_accuracy: 0.5000 - 3s/epoch - 1s/step\n",
      "Epoch 14/18\n",
      "2/2 - 3s - loss: 0.6753 - accuracy: 0.5500 - val_loss: 0.7419 - val_accuracy: 0.5250 - 3s/epoch - 1s/step\n",
      "Epoch 15/18\n",
      "2/2 - 3s - loss: 0.5942 - accuracy: 0.7188 - val_loss: 0.7051 - val_accuracy: 0.5250 - 3s/epoch - 1s/step\n",
      "Epoch 16/18\n",
      "2/2 - 3s - loss: 0.5958 - accuracy: 0.6438 - val_loss: 0.6634 - val_accuracy: 0.5750 - 3s/epoch - 1s/step\n",
      "Epoch 17/18\n",
      "2/2 - 3s - loss: 0.5808 - accuracy: 0.6938 - val_loss: 0.7002 - val_accuracy: 0.5500 - 3s/epoch - 1s/step\n",
      "Epoch 18/18\n",
      "2/2 - 3s - loss: 0.5891 - accuracy: 0.7000 - val_loss: 0.6927 - val_accuracy: 0.6250 - 3s/epoch - 1s/step\n"
     ]
    }
   ],
   "source": [
    "# create data generator\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "# prepare iterators\n",
    "train_it = datagen.flow_from_directory('dogs_vs_squirrel/train/', class_mode='binary', batch_size=80, target_size=(200, 200))\n",
    "test_it = datagen.flow_from_directory('dogs_vs_squirrel/test/', class_mode='binary', batch_size=40, target_size=(200, 200))\n",
    "\n",
    "# fit model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_it, steps_per_epoch=len(train_it), validation_data=test_it, validation_steps=len(test_it), epochs=18, callbacks=[vgg1_callback], verbose=2)\n",
    "training_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9e7e29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "> 70.625\n"
     ]
    }
   ],
   "source": [
    "# Prepare the plot\n",
    "file_writer = tf.summary.create_file_writer(\"logs/vgg1_callback_dir/test_images\")\n",
    "predictions = []\n",
    "for i in test_images:\n",
    "    predictions.append(model.predict(i)[0][0])\n",
    "\n",
    "figure = image_grid(predictions, images)\n",
    "#pyplot.plot(figure)\n",
    "# Convert to image and log\n",
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"Test Images\", plot_to_image(figure), step=0)\n",
    "\n",
    "# Calculate training and testing metrics\n",
    "train_loss, train_accuracy = model.evaluate(train_it, steps=len(train_it), verbose=0)\n",
    "test_loss, test_accuracy = model.evaluate(test_it, steps=len(test_it), verbose=0)\n",
    "\n",
    "# Count the number of model parameters\n",
    "num_params = model.count_params()\n",
    "\n",
    "print('> %.3f' % (train_accuracy * 100.0))\n",
    "# learning curves\n",
    "summarize_diagnostics(history, 'VGG 1 Block ')\n",
    "\n",
    "# Append the Block model metrics to the DataFrame\n",
    "df.loc[0] = [\"VGG (1 blocks)\", training_time, train_loss, train_accuracy, test_accuracy, num_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eac06ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG 3 Block\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile model\n",
    "opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg3_callback = keras.callbacks.TensorBoard(log_dir=\"logs/vgg3_callback_dir\", update_freq = 'batch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37a000fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n",
      "Epoch 1/18\n",
      "2/2 - 6s - loss: 2.4032 - accuracy: 0.5000 - val_loss: 1.3088 - val_accuracy: 0.5000 - 6s/epoch - 3s/step\n",
      "Epoch 2/18\n",
      "2/2 - 6s - loss: 1.1973 - accuracy: 0.4875 - val_loss: 1.0029 - val_accuracy: 0.5000 - 6s/epoch - 3s/step\n",
      "Epoch 3/18\n",
      "2/2 - 5s - loss: 0.9334 - accuracy: 0.5000 - val_loss: 0.7127 - val_accuracy: 0.5000 - 5s/epoch - 3s/step\n",
      "Epoch 4/18\n",
      "2/2 - 5s - loss: 0.7022 - accuracy: 0.5000 - val_loss: 0.6865 - val_accuracy: 0.5250 - 5s/epoch - 3s/step\n",
      "Epoch 5/18\n",
      "2/2 - 6s - loss: 0.6922 - accuracy: 0.4938 - val_loss: 0.6863 - val_accuracy: 0.6750 - 6s/epoch - 3s/step\n",
      "Epoch 6/18\n",
      "2/2 - 6s - loss: 0.6897 - accuracy: 0.5188 - val_loss: 0.6845 - val_accuracy: 0.5750 - 6s/epoch - 3s/step\n",
      "Epoch 7/18\n",
      "2/2 - 6s - loss: 0.6891 - accuracy: 0.5312 - val_loss: 0.6833 - val_accuracy: 0.5250 - 6s/epoch - 3s/step\n",
      "Epoch 8/18\n",
      "2/2 - 6s - loss: 0.6876 - accuracy: 0.5312 - val_loss: 0.6824 - val_accuracy: 0.5500 - 6s/epoch - 3s/step\n",
      "Epoch 9/18\n",
      "2/2 - 6s - loss: 0.6882 - accuracy: 0.5312 - val_loss: 0.6853 - val_accuracy: 0.6750 - 6s/epoch - 3s/step\n",
      "Epoch 10/18\n",
      "2/2 - 6s - loss: 0.6843 - accuracy: 0.6250 - val_loss: 0.6836 - val_accuracy: 0.6000 - 6s/epoch - 3s/step\n",
      "Epoch 11/18\n",
      "2/2 - 6s - loss: 0.6818 - accuracy: 0.5875 - val_loss: 0.6767 - val_accuracy: 0.6250 - 6s/epoch - 3s/step\n",
      "Epoch 12/18\n",
      "2/2 - 6s - loss: 0.6795 - accuracy: 0.5500 - val_loss: 0.6723 - val_accuracy: 0.6000 - 6s/epoch - 3s/step\n",
      "Epoch 13/18\n",
      "2/2 - 6s - loss: 0.6737 - accuracy: 0.6062 - val_loss: 0.6698 - val_accuracy: 0.6000 - 6s/epoch - 3s/step\n",
      "Epoch 14/18\n",
      "2/2 - 8s - loss: 0.6673 - accuracy: 0.6062 - val_loss: 0.6677 - val_accuracy: 0.6000 - 8s/epoch - 4s/step\n",
      "Epoch 15/18\n",
      "2/2 - 7s - loss: 0.6600 - accuracy: 0.6562 - val_loss: 0.6663 - val_accuracy: 0.6250 - 7s/epoch - 3s/step\n",
      "Epoch 16/18\n",
      "2/2 - 7s - loss: 0.6579 - accuracy: 0.6313 - val_loss: 0.6643 - val_accuracy: 0.7000 - 7s/epoch - 3s/step\n",
      "Epoch 17/18\n",
      "2/2 - 7s - loss: 0.6473 - accuracy: 0.7063 - val_loss: 0.6679 - val_accuracy: 0.5750 - 7s/epoch - 4s/step\n",
      "Epoch 18/18\n",
      "2/2 - 8s - loss: 0.6472 - accuracy: 0.6875 - val_loss: 0.6678 - val_accuracy: 0.5500 - 8s/epoch - 4s/step\n",
      "1/1 [==============================] - 0s 243ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 65ms/step\n",
      "1/1 [==============================] - 0s 53ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 84ms/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1/1 [==============================] - 0s 77ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 68ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "1/1 [==============================] - 0s 72ms/step\n",
      "1/1 [==============================] - 0s 82ms/step\n",
      "1/1 [==============================] - 0s 81ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 69ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 86ms/step\n",
      "1/1 [==============================] - 0s 87ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "1/1 [==============================] - 0s 73ms/step\n",
      "1/1 [==============================] - 0s 64ms/step\n",
      "1/1 [==============================] - 0s 96ms/step\n",
      "1/1 [==============================] - 0s 54ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "> 72.500\n"
     ]
    }
   ],
   "source": [
    "# create data generator\n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "# prepare iterators\n",
    "train_it = datagen.flow_from_directory('dogs_vs_squirrel/train/', class_mode='binary', batch_size=80, target_size=(200, 200))\n",
    "test_it = datagen.flow_from_directory('dogs_vs_squirrel/test/', class_mode='binary', batch_size=40, target_size=(200, 200))\n",
    "# fit model\n",
    "start_time = time.time()\n",
    "history = model.fit(train_it, steps_per_epoch=len(train_it), validation_data=test_it, validation_steps=len(test_it), epochs=18, callbacks=[vgg3_callback], verbose=2)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Prepare the plot\n",
    "file_writer = tf.summary.create_file_writer(\"logs/vgg3_callback_dir/test_images\")\n",
    "predictions = []\n",
    "for i in test_images:\n",
    "    predictions.append(model.predict(i)[0][0])\n",
    "\n",
    "figure = image_grid(predictions, images)\n",
    "#pyplot.plot(figure)\n",
    "# Convert to image and log\n",
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"Test Images\", plot_to_image(figure), step=0)\n",
    "    \n",
    "# Calculate training and testing metrics\n",
    "train_loss, train_accuracy = model.evaluate(train_it, steps=len(train_it), verbose=0)\n",
    "test_loss, test_accuracy = model.evaluate(test_it, steps=len(test_it), verbose=0)\n",
    "\n",
    "# Count the number of model parameters\n",
    "num_params = model.count_params()\n",
    "\n",
    "print('> %.3f' % (train_accuracy * 100.0))\n",
    "# learning curves\n",
    "summarize_diagnostics(history, 'VGG 3 Block ')\n",
    "# Append the Block model metrics to the DataFrame\n",
    "df.loc[1] = [\"VGG (3 blocks)\", training_time, train_loss, train_accuracy, test_accuracy, num_params]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "473771e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG 3 Block\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(200, 200, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile model\n",
    "opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg3data_callback = keras.callbacks.TensorBoard(log_dir=\"logs/vgg3data_callback_dir\", update_freq = 'batch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "01feffc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n",
      "Epoch 1/18\n",
      "2/2 - 7s - loss: 1.3300 - accuracy: 0.4625 - val_loss: 0.8800 - val_accuracy: 0.5000 - 7s/epoch - 3s/step\n",
      "Epoch 2/18\n",
      "2/2 - 6s - loss: 0.8402 - accuracy: 0.5000 - val_loss: 0.7029 - val_accuracy: 0.5500 - 6s/epoch - 3s/step\n",
      "Epoch 3/18\n",
      "2/2 - 6s - loss: 0.7497 - accuracy: 0.5188 - val_loss: 0.7300 - val_accuracy: 0.5000 - 6s/epoch - 3s/step\n",
      "Epoch 4/18\n",
      "2/2 - 6s - loss: 0.6881 - accuracy: 0.5312 - val_loss: 0.7317 - val_accuracy: 0.5000 - 6s/epoch - 3s/step\n",
      "Epoch 5/18\n",
      "2/2 - 6s - loss: 0.7249 - accuracy: 0.5000 - val_loss: 0.6913 - val_accuracy: 0.5000 - 6s/epoch - 3s/step\n",
      "Epoch 6/18\n",
      "2/2 - 6s - loss: 0.6915 - accuracy: 0.5125 - val_loss: 0.7041 - val_accuracy: 0.5000 - 6s/epoch - 3s/step\n",
      "Epoch 7/18\n",
      "2/2 - 7s - loss: 0.7143 - accuracy: 0.5000 - val_loss: 0.7036 - val_accuracy: 0.5000 - 7s/epoch - 3s/step\n",
      "Epoch 8/18\n",
      "2/2 - 7s - loss: 0.6875 - accuracy: 0.5375 - val_loss: 0.6812 - val_accuracy: 0.5000 - 7s/epoch - 3s/step\n",
      "Epoch 9/18\n",
      "2/2 - 7s - loss: 0.6934 - accuracy: 0.5125 - val_loss: 0.6926 - val_accuracy: 0.5250 - 7s/epoch - 3s/step\n",
      "Epoch 10/18\n",
      "2/2 - 6s - loss: 0.7010 - accuracy: 0.5063 - val_loss: 0.6828 - val_accuracy: 0.5250 - 6s/epoch - 3s/step\n",
      "Epoch 11/18\n",
      "2/2 - 8s - loss: 0.6828 - accuracy: 0.5688 - val_loss: 0.6853 - val_accuracy: 0.5750 - 8s/epoch - 4s/step\n",
      "Epoch 12/18\n",
      "2/2 - 7s - loss: 0.6806 - accuracy: 0.5688 - val_loss: 0.6919 - val_accuracy: 0.5000 - 7s/epoch - 3s/step\n",
      "Epoch 13/18\n",
      "2/2 - 7s - loss: 0.6819 - accuracy: 0.5562 - val_loss: 0.6896 - val_accuracy: 0.5250 - 7s/epoch - 4s/step\n",
      "Epoch 14/18\n",
      "2/2 - 7s - loss: 0.6789 - accuracy: 0.5813 - val_loss: 0.6804 - val_accuracy: 0.6250 - 7s/epoch - 3s/step\n",
      "Epoch 15/18\n",
      "2/2 - 7s - loss: 0.6753 - accuracy: 0.5688 - val_loss: 0.6788 - val_accuracy: 0.5000 - 7s/epoch - 4s/step\n",
      "Epoch 16/18\n",
      "2/2 - 6s - loss: 0.6768 - accuracy: 0.5437 - val_loss: 0.6768 - val_accuracy: 0.4500 - 6s/epoch - 3s/step\n",
      "Epoch 17/18\n",
      "2/2 - 7s - loss: 0.6731 - accuracy: 0.6000 - val_loss: 0.6783 - val_accuracy: 0.6500 - 7s/epoch - 3s/step\n",
      "Epoch 18/18\n",
      "2/2 - 7s - loss: 0.6688 - accuracy: 0.6313 - val_loss: 0.6777 - val_accuracy: 0.6500 - 7s/epoch - 3s/step\n",
      "1/1 [==============================] - 0s 80ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 60ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 56ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 39ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 57ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 43ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "> 58.750\n"
     ]
    }
   ],
   "source": [
    "#VGG 3 blocks with data augmentation\n",
    "# create data generators\n",
    "#vgg3data_callback = keras.callbacks.TensorBoard(log_dir=\"logs/vgg3data_callback_dir\", update_freq='batch')\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "# prepare iterators\n",
    "train_it = train_datagen.flow_from_directory('dogs_vs_squirrel/train/', class_mode='binary', batch_size=80, target_size=(200, 200))\n",
    "test_it = test_datagen.flow_from_directory('dogs_vs_squirrel/test/', class_mode='binary', batch_size=40, target_size=(200, 200))\n",
    "start_time = time.time()\n",
    "history = model.fit(train_it, steps_per_epoch=len(train_it), validation_data=test_it, validation_steps=len(test_it), epochs=18, callbacks=[vgg3data_callback], verbose=2)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Prepare the plot\n",
    "file_writer = tf.summary.create_file_writer(\"logs/vgg3data_callback_dir/test_images\")\n",
    "predictions = []\n",
    "for i in test_images:\n",
    "    predictions.append(model.predict(i)[0][0])\n",
    "\n",
    "figure = image_grid(predictions, images)\n",
    "#pyplot.plot(figure)\n",
    "# Convert to image and log\n",
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"Test Images\", plot_to_image(figure), step=0)\n",
    "    \n",
    "# Calculate training and testing metrics\n",
    "train_loss, train_accuracy = model.evaluate(train_it, steps=len(train_it), verbose=0)\n",
    "test_loss, test_accuracy = model.evaluate(test_it, steps=len(test_it), verbose=0)\n",
    "\n",
    "# Count the number of model parameters\n",
    "num_params = model.count_params()\n",
    "\n",
    "print('> %.3f' % (train_accuracy * 100.0))\n",
    "\n",
    "# learning curves\n",
    "summarize_diagnostics(history, 'VGG 3 Block w augmentation ')\n",
    "# Append the Block model metrics to the DataFrame\n",
    "df.loc[2] = [\"VGG (3 blocks w augmentation)\", training_time, train_loss, train_accuracy, test_accuracy, num_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5d080a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.models import Model\n",
    "\n",
    "# transfer learning using vgg16\n",
    "\n",
    "model1 = VGG16(include_top=False, input_shape=(200, 200, 3))\n",
    "# mark loaded layers as not trainable\n",
    "for layer in model1.layers:\n",
    "    layer.trainable = False\n",
    " # add new classifier layers\n",
    "flat1 = Flatten()(model1.layers[-1].output)\n",
    "class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
    "output = Dense(1, activation='sigmoid')(class1)\n",
    "# define new model\n",
    "model1 = Model(inputs=model1.inputs, outputs=output)\n",
    "# compile model\n",
    "opt = SGD(learning_rate=0.001, momentum=0.9)\n",
    "model1.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg16_callback = keras.callbacks.TensorBoard(log_dir=\"logs/vgg16_callback_dir\", update_freq='batch')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3cc31b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 160 images belonging to 2 classes.\n",
      "Found 40 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\AppData\\Local\\Temp\\ipykernel_15436\\3302653080.py:9: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model1.fit_generator(train_it, steps_per_epoch=len(train_it),validation_data=test_it, validation_steps=len(test_it), epochs=18, callbacks=[vgg16_callback], verbose=2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "2/2 - 21s - loss: 2.7290 - accuracy: 0.6875 - val_loss: 0.0647 - val_accuracy: 0.9750 - 21s/epoch - 10s/step\n",
      "Epoch 2/18\n",
      "2/2 - 24s - loss: 0.0172 - accuracy: 0.9937 - val_loss: 0.2803 - val_accuracy: 0.9500 - 24s/epoch - 12s/step\n",
      "Epoch 3/18\n",
      "2/2 - 29s - loss: 0.1621 - accuracy: 0.9875 - val_loss: 0.3904 - val_accuracy: 0.9500 - 29s/epoch - 14s/step\n",
      "Epoch 4/18\n",
      "2/2 - 26s - loss: 1.4652e-05 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9750 - 26s/epoch - 13s/step\n",
      "Epoch 5/18\n",
      "2/2 - 25s - loss: 1.0129e-09 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.9750 - 25s/epoch - 13s/step\n",
      "Epoch 6/18\n",
      "2/2 - 25s - loss: 1.7008e-10 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9750 - 25s/epoch - 12s/step\n",
      "Epoch 7/18\n",
      "2/2 - 24s - loss: 1.6161e-10 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9750 - 24s/epoch - 12s/step\n",
      "Epoch 8/18\n",
      "2/2 - 25s - loss: 4.3087e-10 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.9750 - 25s/epoch - 13s/step\n",
      "Epoch 9/18\n",
      "2/2 - 25s - loss: 1.4433e-09 - accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 0.9750 - 25s/epoch - 13s/step\n",
      "Epoch 10/18\n",
      "2/2 - 28s - loss: 3.0090e-09 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.9750 - 28s/epoch - 14s/step\n",
      "Epoch 11/18\n",
      "2/2 - 27s - loss: 5.6800e-09 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9750 - 27s/epoch - 13s/step\n",
      "Epoch 12/18\n",
      "2/2 - 26s - loss: 7.3951e-09 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.9750 - 26s/epoch - 13s/step\n",
      "Epoch 13/18\n",
      "2/2 - 28s - loss: 1.1617e-08 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9750 - 28s/epoch - 14s/step\n",
      "Epoch 14/18\n",
      "2/2 - 26s - loss: 1.9586e-08 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.9750 - 26s/epoch - 13s/step\n",
      "Epoch 15/18\n",
      "2/2 - 26s - loss: 2.2542e-08 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.9750 - 26s/epoch - 13s/step\n",
      "Epoch 16/18\n",
      "2/2 - 26s - loss: 3.2306e-08 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.9750 - 26s/epoch - 13s/step\n",
      "Epoch 17/18\n",
      "2/2 - 26s - loss: 3.9054e-08 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.9750 - 26s/epoch - 13s/step\n",
      "Epoch 18/18\n",
      "2/2 - 26s - loss: 4.5533e-08 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.9750 - 26s/epoch - 13s/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 37ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 46ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "> 100.000\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(featurewise_center=True)\n",
    "# specify imagenet mean values for centering\n",
    "datagen.mean = [123.68, 116.779, 103.939]\n",
    "# prepare iterator\n",
    "train_it = datagen.flow_from_directory('dogs_vs_squirrel/train/', class_mode='binary', batch_size=80, target_size=(200, 200))\n",
    "test_it = datagen.flow_from_directory('dogs_vs_squirrel/test/', class_mode='binary', batch_size=40, target_size=(200, 200))\n",
    " # fit model\n",
    "start_time = time.time()\n",
    "history = model1.fit_generator(train_it, steps_per_epoch=len(train_it),validation_data=test_it, validation_steps=len(test_it), epochs=18, callbacks=[vgg16_callback], verbose=2)\n",
    "training_time = time.time() - start_time\n",
    "\n",
    "# Prepare the plot\n",
    "file_writer = tf.summary.create_file_writer(\"logs/vgg16_callback_dir/test_images\")\n",
    "predictions = []\n",
    "for i in test_images:\n",
    "    predictions.append(model.predict(i)[0][0])\n",
    "\n",
    "figure = image_grid(predictions, images)\n",
    "#pyplot.plot(figure)\n",
    "# Convert to image and log\n",
    "with file_writer.as_default():\n",
    "    tf.summary.image(\"Test Images\", plot_to_image(figure), step=0)\n",
    "    \n",
    "    \n",
    "# Calculate training and testing metrics\n",
    "train_loss, train_accuracy = model1.evaluate(train_it, steps=len(train_it), verbose=0)\n",
    "test_loss, test_accuracy = model1.evaluate(test_it, steps=len(test_it), verbose=0)\n",
    "\n",
    "# Count the number of model parameters\n",
    "num_params = model1.count_params()\n",
    "\n",
    "print('> %.3f' % (train_accuracy * 100.0))\n",
    "\n",
    "# learning curves\n",
    "summarize_diagnostics(history, 'VGG 16')\n",
    "# Append the Block model metrics to the DataFrame\n",
    "df.loc[3] = [\"VGG 16\", training_time, train_loss, train_accuracy, test_accuracy, num_params]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4e5c0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "folder_path = 'dogs_vs_squirrel/train/squirrel'\n",
    "\n",
    "i = 1\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.png'):\n",
    "        new_filename = 'squirrel_' + str(i) + '.png'\n",
    "        src = os.path.join(folder_path, filename)\n",
    "        dst = os.path.join(folder_path, new_filename)\n",
    "        shutil.move(src, dst)\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "520600ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 224, 224, 3) (200,)\n"
     ]
    }
   ],
   "source": [
    "# load dogs vs cats dataset, reshape and save to a new file\n",
    "# dogs -> 1\n",
    "# squirrel -> 0\n",
    "from os import listdir\n",
    "from numpy import asarray\n",
    "from numpy import save\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "# define location of dataset\n",
    "folder = 'train/'\n",
    "photos, labels = list(), list()\n",
    "# enumerate files in the directory\n",
    "for file in listdir(folder):\n",
    "    # determine class\n",
    "    output = 0.0\n",
    "    if file.startswith('dogs'):\n",
    "        output = 1.0\n",
    "    # load image\n",
    "    photo = load_img(folder + file, target_size=(224, 224))\n",
    "    # convert to numpy array\n",
    "    photo = img_to_array(photo)\n",
    "    # store\n",
    "    photos.append(photo)\n",
    "    labels.append(output)\n",
    "    \n",
    "# convert to a numpy arrays\n",
    "photos = asarray(photos)\n",
    "labels = asarray(labels)\n",
    "print(photos.shape, labels.shape)\n",
    "# save the reshaped photos\n",
    "save('dogs_vs_squirrel_photos.npy', photos)\n",
    "save('dogs_vs_squirrel_labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1b211921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed random number generator\n",
    "# organize dataset into a useful structure\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "\n",
    "seed(1)\n",
    "dataset_home = 'dogs_vs_squirrel/'\n",
    "# define ratio of pictures to use for validation\n",
    "val_ratio = 0.2\n",
    "# copy training dataset images into subdirectories\n",
    "src_directory = 'train/'\n",
    "for file in listdir(src_directory):\n",
    "    src = src_directory + '/' + file\n",
    "    dst_dir = 'train/'\n",
    "    if random() < val_ratio:\n",
    "        dst_dir = 'test/'\n",
    "    if file.startswith('Daisy'):\n",
    "        dst = dataset_home + dst_dir + 'Daisy/'  + file\n",
    "        copyfile(src, dst)\n",
    "    elif file.startswith('Sunflower'):\n",
    "        dst = dataset_home + dst_dir + 'Sunflower/'  + file\n",
    "        copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b957749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create an empty DataFrame with the desired columns\n",
    "df = pd.DataFrame(columns=[\"Model\", \"Training time\", \"Training loss\", \"Training accuracy\", \"Testing accuracy\", \"Number of model parameters\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51c1dfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Training time</th>\n",
       "      <th>Training loss</th>\n",
       "      <th>Training accuracy</th>\n",
       "      <th>Testing accuracy</th>\n",
       "      <th>Number of model parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VGG (1 blocks)</td>\n",
       "      <td>49.639443</td>\n",
       "      <td>5.849457e-01</td>\n",
       "      <td>0.70625</td>\n",
       "      <td>0.625</td>\n",
       "      <td>40961153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VGG (3 blocks)</td>\n",
       "      <td>112.006978</td>\n",
       "      <td>6.356205e-01</td>\n",
       "      <td>0.72500</td>\n",
       "      <td>0.550</td>\n",
       "      <td>10333505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>VGG (3 blocks w augmentation)</td>\n",
       "      <td>120.805475</td>\n",
       "      <td>6.752859e-01</td>\n",
       "      <td>0.58750</td>\n",
       "      <td>0.650</td>\n",
       "      <td>10333505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VGG 16</td>\n",
       "      <td>463.923356</td>\n",
       "      <td>4.860777e-08</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.975</td>\n",
       "      <td>17074241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Model  Training time  Training loss  \\\n",
       "0                 VGG (1 blocks)      49.639443   5.849457e-01   \n",
       "1                 VGG (3 blocks)     112.006978   6.356205e-01   \n",
       "2  VGG (3 blocks w augmentation)     120.805475   6.752859e-01   \n",
       "3                         VGG 16     463.923356   4.860777e-08   \n",
       "\n",
       "   Training accuracy  Testing accuracy  Number of model parameters  \n",
       "0            0.70625             0.625                    40961153  \n",
       "1            0.72500             0.550                    10333505  \n",
       "2            0.58750             0.650                    10333505  \n",
       "3            1.00000             0.975                    17074241  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca60ba3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
